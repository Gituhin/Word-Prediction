{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "last_word_pred",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTf31muHts4+1biAHgy4cA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gituhin/Word-Prediction/blob/main/last_word_pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEgX0J5dD068"
      },
      "source": [
        "Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlWo-0T2cIhU"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import string \n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fqsjBuuNnsV"
      },
      "source": [
        "loading the training data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-X9fgBpLVD8"
      },
      "source": [
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "worksheet = gc.open('40').sheet1\n",
        "rows = worksheet.get_all_values()\n",
        "# Convert to a DataFrame and render.\n",
        "data=pd.DataFrame.from_records(rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwNkzAmlc9sO"
      },
      "source": [
        "function for preprocessing a line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIlvyxJ4UtqV"
      },
      "source": [
        "def preprocessline(data, c):\n",
        "  step=str.maketrans('','',string.punctuation)    #removing punctuations\n",
        "  line=data[0][c].translate(step) \n",
        "  line=line.lower()       #converting all words to lower cases and splitting them\n",
        "  words=line.split()\n",
        "\n",
        "  st_words=stopwords.words('english')\n",
        "  i=0\n",
        "  while i<len(words):\n",
        "    if words[i] in st_words:     #removing the stop words, finding them and poping them out from the words splitted list\n",
        "      words.pop(i)\n",
        "      i=0\n",
        "    i+=1\n",
        "  ps = PorterStemmer()           #using porter stemmer to convert to root words\n",
        "  for w in range(len(words)):\n",
        "    words[w]=(ps.stem(words[w]))\n",
        "  return words                    #returning the processed words in a line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI3-wsngqEDo"
      },
      "source": [
        "Creating set of unique words (to use as references for creating vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_33myPaHEf-"
      },
      "source": [
        "word_setfinal=set()\n",
        "for i in range(1, len(data)):\n",
        "  word_setfinal.update(preprocessline(data, i))     #creating a collection of unique words in the document. The set has been used to avoid repeatitions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMDJznDBqAbt"
      },
      "source": [
        "creating vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkbq4E9yfBxv"
      },
      "source": [
        "vocabulary={}\n",
        "for wds in word_setfinal:         #creating vocabulary of all words, Dictionary has beed used to keep words in key and frequencies in values.\n",
        "  vocabulary[wds]=0                 #setting initial frequency to 0 for all\n",
        "\n",
        "for i in range(1, len(data)):\n",
        "  words_in_line=preprocessline(data, i)\n",
        "  for wd in word_setfinal:\n",
        "    for c in range(len(words_in_line)):\n",
        "      if wd==words_in_line[c]:\n",
        "        vocabulary[wd]+=1                     #if word has occurred a numer of times the value of the key is increased by 1 and finally frequency is calculated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDrYEMhSp5GO"
      },
      "source": [
        "Prior distribuion of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfbjDPQ3o-rh"
      },
      "source": [
        "prob_words={}       #prior distribution dictionary\n",
        "total_sum=0\n",
        "for g in vocabulary:\n",
        "  total_sum+=vocabulary[g]      #calculating total number of words in the document\n",
        "\n",
        "for h in vocabulary:\n",
        "  prob_words[h]=vocabulary[h]/total_sum             #prior distribution is frequency of the word upon total words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv0ciT31d5F1"
      },
      "source": [
        "class conditional probabilities of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk2fUZbz2Wde"
      },
      "source": [
        "doc_lst=[]                  #storing all the processed words of a line separately in a list to reduce time complexity of processing in the below block\n",
        "for i in range(1, len(data)):\n",
        "  doc_lst.append(preprocessline(data, i))\n",
        "sent={}\n",
        "for wd in word_setfinal:\n",
        "  c=0\n",
        "  for i in range(len(doc_lst)):         #storing the number of sentences in which a particular word appears in sent dictionary\n",
        "    if wd in doc_lst[i]:\n",
        "      c+=1\n",
        "  sent[wd]=c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxDxtdzBqS-Q"
      },
      "source": [
        "cc_prob=[]                # creating a list of tuples, where first element is a word and second element is a dictionary consisting of \n",
        "for wod1 in word_setfinal:  #other words as keys and the class conditional probabilty of first element word over the keys as the values\n",
        "  d=dict()\n",
        "  for wod2 in word_setfinal:\n",
        "    c=0\n",
        "    for i in range(len(doc_lst)):\n",
        "      if wod1 in doc_lst[i] and wod2 in doc_lst[i]: #checking if both words are in same sentence and then increasing the counter\n",
        "        c+=1\n",
        "      if c!=0:\n",
        "        d[wod2]=c/sent[wod1]\n",
        "      else:\n",
        "        d[wod2]=0.0001      #if they aren't in same sentences in all the sentences of document then assigning a small probabilty close to 0\n",
        "  cc_prob.append((wod1, d))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aE9KghX_aNE"
      },
      "source": [
        "Applying on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7nntAdA_ZmP"
      },
      "source": [
        "worksheet1 = gc.open('10').sheet1\n",
        "rows = worksheet1.get_all_values()\n",
        "# Convert to a DataFrame and render.\n",
        "data_test=pd.DataFrame.from_records(rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELirARl2OErL"
      },
      "source": [
        "posterior distribution of words for a sentence and predicting most likely word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoMDN2cmITnw"
      },
      "source": [
        "def idx(lst, word):     #function to return index of the word in 2nd element of dictionary for class conditonal probability\n",
        "  j=0\n",
        "  while word!=lst[j][0]:\n",
        "    j+=1\n",
        "  return j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YccN__dc4qYt"
      },
      "source": [
        "for f in range(1, len(data_test)):\n",
        "  p_list={}          #dictionary for storing all the probabiltiies of the words for a sentence\n",
        "  words=preprocessline(data_test, f)\n",
        "  for wd in word_setfinal:\n",
        "    prob=1\n",
        "    for w in words:\n",
        "      if w not in word_setfinal:      #if the word in testset is not in trainset then adjusting the probabability to small and close to 0\n",
        "        prob=0.0001\n",
        "      else:\n",
        "        i=idx(cc_prob, w)\n",
        "      prob*=cc_prob[i][1][wd]\n",
        "    prob=prob*prob_words[wd]\n",
        "    p_list[wd]=prob\n",
        "  probable_word = max(p_list, key=p_list.get)\n",
        "  print('The most suitable word is', probable_word)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}